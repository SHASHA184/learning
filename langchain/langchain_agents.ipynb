{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Agents: Building Intelligent Tool-Using Systems\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Agents** are LLM-powered systems that can decide which tools to use and in what order to accomplish tasks. They enable dynamic, multi-step reasoning and action.\n",
    "\n",
    "### What Are Agents?\n",
    "\n",
    "Agents allow LLMs to:\n",
    "- **Use tools dynamically**: Search, calculate, query databases\n",
    "- **Make decisions**: Choose which tool to use based on context\n",
    "- **Multi-step reasoning**: Chain multiple tool calls together\n",
    "- **Handle complex tasks**: Break down problems into sub-tasks\n",
    "- **Adapt to results**: Use tool output to inform next steps\n",
    "\n",
    "### Agent vs Chain\n",
    "\n",
    "| Chain | Agent |\n",
    "|-------|-------|\n",
    "| Predefined sequence | Dynamic decision-making |\n",
    "| Fixed steps | Adaptive steps |\n",
    "| No tool selection | Chooses tools |\n",
    "| Deterministic | Non-deterministic |\n",
    "\n",
    "### When to Use Agents?\n",
    "\n",
    "| ‚úÖ Use Agents For | ‚ùå Don't Use For |\n",
    "|-------------------|------------------|\n",
    "| Dynamic tool selection | Simple fixed workflows |\n",
    "| Multi-step reasoning | Single LLM call |\n",
    "| Unknown number of steps | Known sequence |\n",
    "| Complex problem solving | Simple Q&A |\n",
    "\n",
    "### ReAct Pattern\n",
    "\n",
    "Most agents use **ReAct** (Reasoning + Acting):\n",
    "\n",
    "1. **Thought**: Reason about what to do\n",
    "2. **Action**: Choose and execute a tool\n",
    "3. **Observation**: See the result\n",
    "4. **Repeat**: Until task is complete\n",
    "\n",
    "---\n",
    "\n",
    "## Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key configured!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# !pip install langchain langchain-openai langchain-community\n",
    "# !pip install duckduckgo-search wikipedia\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Set API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API Key: \")\n",
    "\n",
    "print(\"API key configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 1: Simple Custom Tool\n",
    "\n",
    "Create a basic tool with the `@tool` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: multiply\n",
      "Description: Multiply two numbers together.\n",
      "Args: {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n",
      "\n",
      "Result: 35\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers together.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# Inspect the tool\n",
    "print(f\"Name: {multiply.name}\")\n",
    "print(f\"Description: {multiply.description}\")\n",
    "print(f\"Args: {multiply.args}\")\n",
    "\n",
    "# Use the tool directly\n",
    "result = multiply.invoke({\"a\": 5, \"b\": 7})\n",
    "print(f\"\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 2: Multiple Custom Tools\n",
    "\n",
    "Create a toolkit of related tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def subtract(a: float, b: float) -> float:\n",
    "    \"\"\"Subtract b from a.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide(a: float, b: float) -> float:\n",
    "    \"\"\"Divide a by b.\"\"\"\n",
    "    if b == 0:\n",
    "        return \"Error: Division by zero\"\n",
    "    return a / b\n",
    "\n",
    "# Create toolkit\n",
    "math_tools = [add, subtract, multiply, divide]\n",
    "\n",
    "print(\"Math toolkit:\")\n",
    "for tool in math_tools:\n",
    "    print(f\"- {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 3: Creating an Agent\n",
    "\n",
    "Build an agent that can use tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "tools = [get_word_length]\n",
    "\n",
    "# Get prompt template\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# Create LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Create agent\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "# Create agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Run agent\n",
    "result = agent_executor.invoke({\"input\": \"How many letters are in the word 'intelligence'?\"})\n",
    "print(f\"\\nFinal answer: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "The agent:\n",
    "1. **Reasoned**: Understood it needed to find word length\n",
    "2. **Selected tool**: Chose `get_word_length`\n",
    "3. **Called tool**: With argument \"intelligence\"\n",
    "4. **Returned result**: 12 letters\n",
    "\n",
    "---\n",
    "\n",
    "## Example 4: Agent with Calculator Tools\n",
    "\n",
    "Multi-step mathematical reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Math toolkit\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def power(base: float, exponent: float) -> float:\n",
    "    \"\"\"Raise base to the power of exponent.\"\"\"\n",
    "    return base ** exponent\n",
    "\n",
    "tools = [add, multiply, power]\n",
    "\n",
    "# Create agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Complex calculation requiring multiple steps\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"What is (5 + 3) multiplied by 2, and then raise that to the power of 2?\"\n",
    "})\n",
    "\n",
    "print(f\"\\nFinal answer: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 5: Built-in Tools - Web Search\n",
    "\n",
    "Use DuckDuckGo for web searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Create search tool\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "# Create agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Search the web\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"What is the current version of Python?\"\n",
    "})\n",
    "\n",
    "print(f\"\\nAnswer: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 6: Built-in Tools - Wikipedia\n",
    "\n",
    "Query Wikipedia for information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Create Wikipedia tool\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "tools = [wikipedia]\n",
    "\n",
    "# Create agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Query Wikipedia\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"Who was Alan Turing and what did he contribute to computer science?\"\n",
    "})\n",
    "\n",
    "print(f\"\\nAnswer: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 7: Combining Multiple Tools\n",
    "\n",
    "Agent can choose from multiple tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from datetime import datetime\n",
    "\n",
    "# Custom tools\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "@tool\n",
    "def calculate_age(birth_year: int) -> int:\n",
    "    \"\"\"Calculate age from birth year.\"\"\"\n",
    "    current_year = datetime.now().year\n",
    "    return current_year - birth_year\n",
    "\n",
    "# Built-in tool\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "# Combine tools\n",
    "tools = [get_current_time, calculate_age, search]\n",
    "\n",
    "# Create agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Test different tools\n",
    "questions = [\n",
    "    \"What time is it right now?\",\n",
    "    \"How old would someone born in 1990 be?\",\n",
    "    \"Search for the latest Python release\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    result = agent_executor.invoke({\"input\": question})\n",
    "    print(f\"Answer: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 8: Tool with Complex Input Schema\n",
    "\n",
    "Define tools with Pydantic for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Define input schema\n",
    "class StudentInfo(BaseModel):\n",
    "    \"\"\"Input for student grade calculation.\"\"\"\n",
    "    name: str = Field(description=\"Student's name\")\n",
    "    grades: List[float] = Field(description=\"List of grades\")\n",
    "    weights: List[float] = Field(default=None, description=\"Optional weights for grades\")\n",
    "\n",
    "@tool(args_schema=StudentInfo)\n",
    "def calculate_student_average(name: str, grades: List[float], weights: List[float] = None) -> str:\n",
    "    \"\"\"Calculate a student's weighted or unweighted grade average.\"\"\"\n",
    "    if weights:\n",
    "        if len(grades) != len(weights):\n",
    "            return \"Error: grades and weights must have same length\"\n",
    "        avg = sum(g * w for g, w in zip(grades, weights)) / sum(weights)\n",
    "    else:\n",
    "        avg = sum(grades) / len(grades)\n",
    "    \n",
    "    return f\"{name}'s average: {avg:.2f}\"\n",
    "\n",
    "# Test the tool\n",
    "result = calculate_student_average.invoke({\n",
    "    \"name\": \"Alice\",\n",
    "    \"grades\": [85, 90, 88],\n",
    "    \"weights\": [1, 2, 1]\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 9: Agent with Memory\n",
    "\n",
    "Create an agent that remembers conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Create tool\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [multiply]\n",
    "\n",
    "# Create agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "# Add memory\n",
    "message_history = InMemoryChatMessageHistory()\n",
    "\n",
    "agent_with_memory = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "# Conversation with memory\n",
    "config = {\"configurable\": {\"session_id\": \"test-session\"}}\n",
    "\n",
    "print(\"First question:\")\n",
    "result = agent_with_memory.invoke(\n",
    "    {\"input\": \"What is 5 times 7?\"},\n",
    "    config=config\n",
    ")\n",
    "print(f\"Answer: {result['output']}\\n\")\n",
    "\n",
    "print(\"Follow-up (uses memory):\")\n",
    "result = agent_with_memory.invoke(\n",
    "    {\"input\": \"What was my previous question?\"},\n",
    "    config=config\n",
    ")\n",
    "print(f\"Answer: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 10: ReAct Agent (Explicit Reasoning)\n",
    "\n",
    "See the agent's reasoning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_temperature(city: str) -> str:\n",
    "    \"\"\"Get the temperature for a city (mock data).\"\"\"\n",
    "    temps = {\n",
    "        \"new york\": \"15¬∞C\",\n",
    "        \"london\": \"12¬∞C\",\n",
    "        \"tokyo\": \"18¬∞C\"\n",
    "    }\n",
    "    return temps.get(city.lower(), \"Temperature data not available\")\n",
    "\n",
    "@tool\n",
    "def compare_numbers(a: float, b: float) -> str:\n",
    "    \"\"\"Compare two numbers and return which is larger.\"\"\"\n",
    "    if a > b:\n",
    "        return f\"{a} is greater than {b}\"\n",
    "    elif b > a:\n",
    "        return f\"{b} is greater than {a}\"\n",
    "    else:\n",
    "        return f\"{a} and {b} are equal\"\n",
    "\n",
    "tools = [get_temperature, compare_numbers]\n",
    "\n",
    "# Create ReAct agent\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Run agent (see Thought, Action, Observation pattern)\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"Is it warmer in New York or Tokyo?\"\n",
    "})\n",
    "\n",
    "print(f\"\\nFinal answer: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Agent Types Comparison\n",
    "\n",
    "### OpenAI Functions Agent\n",
    "- **Best for**: Modern applications (recommended)\n",
    "- **Pros**: Reliable, fast, good tool selection\n",
    "- **Cons**: Requires OpenAI models with function calling\n",
    "\n",
    "### ReAct Agent\n",
    "- **Best for**: Explicit reasoning, debugging\n",
    "- **Pros**: Shows thinking process, works with any LLM\n",
    "- **Cons**: Slower, more tokens\n",
    "\n",
    "### Structured Chat Agent\n",
    "- **Best for**: Complex tool inputs\n",
    "- **Pros**: Handles structured data well\n",
    "- **Cons**: More verbose\n",
    "\n",
    "### Conversational Agent\n",
    "- **Best for**: Chat applications\n",
    "- **Pros**: Built-in memory\n",
    "- **Cons**: Legacy, prefer OpenAI Functions\n",
    "\n",
    "---\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "### ‚úÖ Do\n",
    "\n",
    "1. **Write clear tool descriptions** (agent uses these to decide)\n",
    "2. **Keep tools focused** (one tool = one task)\n",
    "3. **Validate inputs** (use Pydantic schemas)\n",
    "4. **Set max_iterations** (prevent infinite loops)\n",
    "5. **Use verbose=True** during development (see reasoning)\n",
    "6. **Handle errors** (tools can fail)\n",
    "7. **Test tools independently** before giving to agent\n",
    "\n",
    "### ‚ùå Don't\n",
    "\n",
    "1. **Don't make tools too complex** (agent can't use effectively)\n",
    "2. **Don't skip descriptions** (agent won't know when to use)\n",
    "3. **Don't use agents for simple tasks** (chains are better)\n",
    "4. **Don't give too many tools** (agent gets confused, <10 recommended)\n",
    "5. **Don't forget rate limits** (tools may call external APIs)\n",
    "6. **Don't trust blindly** (validate agent outputs)\n",
    "\n",
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "### ‚ùå Mistake 1: Vague Tool Descriptions\n",
    "\n",
    "```python\n",
    "# Bad - agent won't know when to use\n",
    "@tool\n",
    "def process(data):\n",
    "    \"\"\"Process data.\"\"\"\n",
    "    pass\n",
    "```\n",
    "\n",
    "**Solution**: Be specific:\n",
    "```python\n",
    "@tool\n",
    "def calculate_average(numbers: List[float]) -> float:\n",
    "    \"\"\"Calculate the arithmetic mean of a list of numbers.\"\"\"\n",
    "    return sum(numbers) / len(numbers)\n",
    "```\n",
    "\n",
    "### ‚ùå Mistake 2: No Max Iterations\n",
    "\n",
    "```python\n",
    "# Bad - can run forever\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "```\n",
    "\n",
    "**Solution**: Set limits:\n",
    "```python\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    max_iterations=5,\n",
    "    max_execution_time=60  # seconds\n",
    ")\n",
    "```\n",
    "\n",
    "### ‚ùå Mistake 3: Too Many Tools\n",
    "\n",
    "```python\n",
    "# Bad - agent gets confused with 20+ tools\n",
    "tools = [tool1, tool2, ..., tool25]\n",
    "```\n",
    "\n",
    "**Solution**: Group related tools or use tool selection:\n",
    "```python\n",
    "# Keep to <10 tools, or create specialized agents\n",
    "math_tools = [add, subtract, multiply, divide]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Practice Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Create a file management agent\n",
    "# Tools: create_file, read_file, delete_file\n",
    "# Test: \"Create a file called test.txt with content 'Hello World'\"\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Your code here:\n",
    "@tool\n",
    "def create_file(filename: str, content: str) -> str:\n",
    "    \"\"\"Create a file with given content.\"\"\"\n",
    "    # Implement (use a dict to simulate filesystem)\n",
    "    pass\n",
    "\n",
    "# Add read_file and delete_file tools\n",
    "# Create and test agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Build a research agent\n",
    "# Combine Wikipedia + Web Search tools\n",
    "# Test: \"Research the history of Python programming language\"\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun, DuckDuckGoSearchRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Your code here:\n",
    "# Create tools, agent, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Create a data analysis agent\n",
    "# Tools: calculate_mean, calculate_median, find_max, find_min\n",
    "# Test: \"What's the average and maximum of [10, 20, 30, 40, 50]?\"\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "\n",
    "# Your code here:\n",
    "@tool\n",
    "def calculate_mean(numbers: List[float]) -> float:\n",
    "    \"\"\"Calculate the arithmetic mean of a list of numbers.\"\"\"\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "# Add other statistical tools\n",
    "# Create and test agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### ‚úÖ What We Learned\n",
    "\n",
    "1. **Agents**: LLMs that decide which tools to use dynamically\n",
    "2. **ReAct Pattern**: Thought ‚Üí Action ‚Üí Observation loop\n",
    "3. **@tool Decorator**: Create custom tools easily\n",
    "4. **Built-in Tools**: DuckDuckGo, Wikipedia, and more\n",
    "5. **Agent Types**: OpenAI Functions (best), ReAct, Structured Chat\n",
    "6. **AgentExecutor**: Runs agents with safety limits\n",
    "7. **Tool Schemas**: Pydantic for complex inputs\n",
    "8. **Memory**: Agents can remember conversation context\n",
    "9. **Best Practices**: Clear descriptions, focused tools, max iterations\n",
    "\n",
    "### ‚ö†Ô∏è Important Warnings\n",
    "\n",
    "1. **Agents are non-deterministic** - same input may produce different outputs\n",
    "2. **Can be expensive** - multiple LLM calls per task\n",
    "3. **May fail** - agent might not complete task correctly\n",
    "4. **Validate outputs** - always check agent results\n",
    "5. **Set limits** - max_iterations, max_execution_time\n",
    "6. **Not for production-critical** paths without extensive testing\n",
    "\n",
    "### üìö Next Steps\n",
    "\n",
    "- **langchain_memory.ipynb**: Advanced memory patterns\n",
    "- **LangGraph**: For complex multi-agent systems\n",
    "- Production agents: Monitoring, fallbacks, human-in-the-loop\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Agents Documentation](https://python.langchain.com/docs/modules/agents/)\n",
    "- [Tools Documentation](https://python.langchain.com/docs/modules/agents/tools/)\n",
    "- [ReAct Paper](https://arxiv.org/abs/2210.03629)\n",
    "- [Agent Types](https://python.langchain.com/docs/modules/agents/agent_types/)\n",
    "- [Custom Tools Guide](https://python.langchain.com/docs/modules/agents/tools/custom_tools)\n",
    "\n",
    "---\n",
    "\n",
    "**Next Notebook**: `langchain_memory.ipynb` - Conversation memory patterns and strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
